{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Aakef Waris <br>\n",
    "Course: CS-422<br>\n",
    "Date Due: Februrary, 8, 2020\n",
    "\n",
    "# Homework 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recitation Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Discuss whether or not each of the following activities is a data mining task.\n",
    "\n",
    "##### a) Dividing the customers of a company according to their gender.\n",
    "\n",
    "   - No not really. We either have to be predicting or describing data.\n",
    "\n",
    "##### b) Dividing the customers of a company according to their profitability.\n",
    "    \n",
    "   - No, it's the same reason as part A, there's no prediction, nor is there any pattern recognition\n",
    "    \n",
    "##### c) Computing the total sales of a company.\n",
    "    \n",
    "   - No, same reason as before.\n",
    "\n",
    "##### d) Sorting a student database based on student identification numbers.\n",
    "    \n",
    "   - No, this is a simple query\n",
    "\n",
    "##### e) Predicting the outcomes of tossing a (fair) pair of dice.\n",
    "    \n",
    "   - Yes, (prediction) however useless, as prior dice data cannot predict future roles.\n",
    "\n",
    "##### f) Predicting the future stock price of a company using historical records.\n",
    "    \n",
    "   - Yes, this is predictive modeling\n",
    "\n",
    "##### g) Monitoring the heart rate of a patient for abnormalities.\n",
    "    \n",
    "   - No, this is just collection, not prediction or classification\n",
    "\n",
    "##### h) Monitoring seismic waves for earthquake activities.\n",
    "\n",
    "   - No, there's no prediction or classification\n",
    "\n",
    "##### i) Extracting the frequencies of a sound wave.\n",
    "\n",
    "   - No, This is just data collection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Classify the following attributes as binary, discrete, or continuous. Also classify them as qualitative (nominal or ordinal) or quantitative (interval or ratio). Some cases may have more than one interpretation, so briefly indicate your reasoning if you think there may be some ambiguity.\n",
    "\n",
    "#### Example: Age in years. Answer: Discrete, quantitative, ratio\n",
    "\n",
    "##### a) Time in terms of AM or PM.\n",
    "\n",
    "   - discrete, quantitative, interval \n",
    "\n",
    "##### b) Brightness as measured by a light meter.\n",
    "\n",
    "   - continuous, quantitative, ratio \n",
    "\n",
    "##### c) Brightness as measured by people’s judgments.\n",
    "\n",
    "   - discrete, qualitative, ordinal (ex. \"That's really bright\" vs \"That's kinda bright\")\n",
    "\n",
    "##### d) Angles as measured in degrees between 0 and 360.\n",
    "    \n",
    "   - discrete, quantitative, ratio\n",
    "\n",
    "##### e) Bronze, Silver, and Gold medals as awarded at the Olympics.\n",
    "    \n",
    "   - discrete, qualitative, ordinal\n",
    "    \n",
    "##### f) Height above sea level.\n",
    "    \n",
    "   - continuous, quantitative, interval\n",
    "    \n",
    "##### g) Number of patients in a hospital.\n",
    "\n",
    "   - discrete, quantitative, interval\n",
    "\n",
    "##### h) ISBN numbers for books. (Look up the format on the Web.)\n",
    "   \n",
    "   - discrete, qualitative, nominal\n",
    "\n",
    "##### i) Ability to pass light in terms of the following values: opaque, translucent, transparent.\n",
    "\n",
    "   - discrete, qualitative, ordinal \n",
    "\n",
    "##### j) Military rank.\n",
    "\n",
    "   - discrete, qualitative, ordinal\n",
    "\n",
    "##### k) Distance from the center of campus.\n",
    "\n",
    "   - continuous, quantitative, interval\n",
    "\n",
    "##### l) Density of a substance in grams per cubic centimeter.\n",
    "\n",
    "   - continuous, quantitative, ratio\n",
    "\n",
    "##### m) Coat check number. (When you attend an event, you can often give your coat to someone who, in turn, gives you a number that you can use to claim your coat when you leave.)\n",
    "\n",
    "   - discrete, quantitative, nominal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Which of the following quantities is likely to show more temporal autocorrelation: daily rainfall or daily temperature? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Daily temperature, primarily becuase, temperature from day to day is relatively similar in most climates, however when discussing rain, unless the climate is particularly rainy, we wouldn't see multiple days of rain. Becuase of the way the water cycle works, water would have to evaporate and build up in the clouds for it to rain again. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15) You are given a set of m objects that is divided into k groups, where the ith group is of size $m_i$\n",
    "### If the goal is to obtain a sample of size n < m, what is the difference between the following two sampling schemes? (Assume sampling with replacement.)\n",
    "\n",
    "##### a) We randomly select $\\frac{(n×m_i)}{m}$ elements from each group.\n",
    "\n",
    "##### b) We randomly select $n$ elements from the data set, without regard for the group to which an object belongs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The difference between the two schemes is that in 'a', We get a representative sample size of each group m, however, in 'b', we do not, and the sample, is not representative of the set of 'm' objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16) Consider a document-term matrix, where $tf_{ij}$ is the frequency of the $i^{th}$ word (term) in the $j^{th}$ document and $m$ is the number of documents. Consider the variable transformation that is defined by \n",
    "\n",
    "### $tf' _{ij}=tf_{ij}×log(\\frac{m}{df_{i}})$ \n",
    "\n",
    "### where $df_i$ is the number of documents in which the $i^{th}$ term appears, which is known as the document frequency of the term. This transformation is known as the inverse document frequency transformation.\n",
    "\n",
    "##### a) What is the effect of this transformation if a term occurs in one document? In every document?\n",
    "\n",
    "   - We can see that if a word occurs in 1 document, then the resultant frequency value increases depending on the total documents, \n",
    "   - If this word occurs in all documents the frequency drops to 0\n",
    "\n",
    "##### b) What might be the purpose of this transformation?\n",
    "\n",
    "   - The purpose of this transform might be to emphasize documents that have high occurances of words that are not commonly used. The only time we will see a high value, is when the number of docuemnts where a given term occurs, is low, but we see that term occur quite often in a few documents relative to the total amount of documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17) Assume that we apply a square root transformation to a ratio attribute $x$ to obtain the new attribute $x^*$. As part of your analysis, you identify an interval (a, b) in which $x^*$ has a linear relationship to another attribute $y$.\n",
    "\n",
    "##### a) What is the corresponding interval (A, B) in terms of x ?\n",
    "\n",
    "- $(\\sqrt{A}, \\sqrt{B})$\n",
    "\n",
    "##### b) Give an equation that relates y to x.\n",
    "\n",
    "- $y = \\sqrt{x} + b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18) This exercise compares and contrasts some similarity and distance measures. For binary data, the L1 distance corresponds to the Hamming distance; that is, the number of bits that are different between two binary vectors. The Jaccard similarity is a measure of the similarity between two binary vectors. \n",
    "\n",
    "##### a) Compute the Hamming distance and the Jaccard similarity between the following two binary vectors. \n",
    "##### $x = 0101010001$\n",
    "##### $y = 0100011000$\n",
    "\n",
    "   - Hamming distance: 3\n",
    "   - Jaccard similarity: 2/5\n",
    "\n",
    "\n",
    "\n",
    "##### b) Which approach, Jaccard or Hamming distance, is more similar to the Simple Matching Coefficient, and which approach is more similar to the cosine measure? Explain. (Note: The Hamming measure is a distance, while the other three measures are similarities, but don’t let this confuse you.)\n",
    "\n",
    "   - The jaccard similarity is more similar to to the cosine measure, becuase they both ignore 0 to 0 measures\n",
    "   - The hamming distance is similar to the simple matching coefficant because the simple matching coeffiant is just: 1 - (hamming distance / # of data points)\n",
    "\n",
    "##### c)Suppose that you are comparing how similar two organisms of different species are in terms of the number of genes they share. Describe which measure, Hamming or Jaccard, you think would be more appropriate for comparing the genetic makeup of two organisms. Explain. (Assume that each animal is represented as a binary vector, where each attribute is 1 if a particular gene is present in the organism and 0 otherwise.)\n",
    "\n",
    "   - I think taking the Jaccard similarity would make most sense here because, in this case we don't really care about the genes that the organisims don't share. So it's best to use a measurement that ignores 0 to 0 matches\n",
    "     \n",
    "\n",
    "##### d) If you wanted to compare the genetic makeup of two organisms of the same species, e.g., two human beings, would you use the Hamming distance, the Jaccard coefficient, or a different measure of similarity or distance? Explain. (Note that two human beings share  $> 99.9\\%$ of the same genes.)\n",
    "\n",
    "   - I think the hamming distance would be better because the focus here is on the genes that are dissimialar. If two humans have 99.9% genes in common, we would just see a Jaccard similarties really close to 1.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. For the following vectors, x and y, calculate the indicated similarity or distance measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VectorPair(object):\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def correlation(self):\n",
    "        toInt = lambda s : int(s)\n",
    "\n",
    "        def std_deviation(vector):\n",
    "            size = len(vector)\n",
    "            mean = sum(map(toInt, vector)) / size\n",
    "            squareDiff = lambda x : (x - mean)**2\n",
    "            return ((1 / (size-1)) * (sum (map(squareDiff, (map(toInt, vector)))))) ** (1 / 2)\n",
    "\n",
    "        def covariance(x, y):\n",
    "            sizeX = len(x)\n",
    "            sizeY = len(y)\n",
    "            meanX = sum(map(toInt, x)) / sizeX\n",
    "            meanY = sum(map(toInt, y)) / sizeY\n",
    "\n",
    "            func = lambda tup : (tup[0] - meanX) * (tup[1] - meanY)\n",
    "\n",
    "            return (1 / (sizeX-1)) * sum(map(func, zip(map(toInt, x), map(toInt, y))))\n",
    "\n",
    "        try:\n",
    "            return covariance(self.x, self.y) / (std_deviation(self.x) * std_deviation(self.y))\n",
    "        except:\n",
    "            return 'undefined'\n",
    "\n",
    "    def cosineSimilarity(self):\n",
    "        dotProduct = sum(map(lambda tup: int(tup[0]) * int(tup[1]), zip(self.x, self.y)))\n",
    "        magnX = (sum(map(lambda n : int(n)**2, self.x))) ** (1/2)\n",
    "        magnY = (sum(map(lambda n: int(n)**2, self.y))) ** (1/2)\n",
    "        return dotProduct / (magnX * magnY)\n",
    "\n",
    "    def euclideanDistance(self):\n",
    "        return sum(map(lambda tup: (tup[0] - tup[1])**2  ,zip(self.x, self.y)))\n",
    "\n",
    "    def jaccard(self):\n",
    "        numerator = sum(map(lambda tup: 1 if tup[0] == 1 and tup[1]== 1 else 0 ,zip(self.x, self.y)))\n",
    "        denominator = sum(map(lambda tup: 1 if tup[0] != 0 or tup[1] != 0 else 0, zip(self.x, self.y)))\n",
    "        return numerator / denominator\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a) x = (1, 1, 1, 1), y = (2, 2, 2, 2) cosine, correlation, Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp = VectorPair((1, 1, 1, 1),(2, 2, 2, 2))\n",
    "print(\"Correlation:\", vp.correlation())\n",
    "print(\"Cosine Similarity:\", vp.cosineSimilarity())\n",
    "print(\"Euclidean Distance:\",vp.euclideanDistance())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b) x = (0, 1, 0, 1), y = (1, 0, 1, 0) cosine, correlation, Euclidean, Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp = VectorPair((0, 1, 0, 1),(1, 0, 1, 0))\n",
    "print(\"Cosine Similarity:\", vp.cosineSimilarity())\n",
    "print(\"Correlation:\", vp.correlation())\n",
    "print(\"Euclidean Distance:\",vp.euclideanDistance())\n",
    "print(\"Jaccard:\", vp.jaccard())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c) x = (0, -1, 0, 1), y = (1, 0, 1, 0)  cosine, correlation, Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp = VectorPair((0, -1, 0, 1),(1, 0, 1, 0))\n",
    "print(\"Cosine Similarity:\", vp.cosineSimilarity())\n",
    "print(\"Correlation:\", vp.correlation())\n",
    "print(\"Euclidean Distance:\",vp.euclideanDistance())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### d) x = (1, 1, 0, 1, 0, 1), y = (1, 1, 1, 0, 0, 1) cosine, correlation, Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp = VectorPair((1, 1, 0, 1, 0, 1),(1, 1, 1, 0, 0, 1))\n",
    "print(\"Cosine Similarity:\", vp.cosineSimilarity())\n",
    "print(\"Correlation:\", vp.correlation())\n",
    "print(\"Jaccard:\",vp.jaccard())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### e) x = (2, -1, 0, 2, -3), y = (-1, 1, -1, 0, 0, -1) cosine, correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp = VectorPair((2, -1, 0, 2, 3),(-1, 1, -1, 0, 0, -1))\n",
    "print(\"Cosine Similarity:\", vp.cosineSimilarity())\n",
    "print(\"Correlation:\", vp.correlation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practicum Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sn.load_dataset('titanic')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived = df[df.survived == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we take a distibution of males vs femaes who survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived['sex'].hist(bins=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It is evident here that way more females survived than males. This actually makes sense because, they saved women first on the life boats, then the men"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we take the distribution of ages among those who survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived['age'].hist(bins=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We see the majority of people who survived, were between 20-40, however it is very likely that most of the people who were on the ship were in there 20s and 30s as they'd have both the financial and physical ability to travel independently, something we see here is that the amount of kids under 5 that survived is relatively close to the people that survived in there 20s, even though there were probably a lot less 5 year olds. This would make sense becuase children were probably prioritized in saving on the ship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
